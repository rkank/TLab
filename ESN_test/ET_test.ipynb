{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from echotorch.nn import ESN, LiESN\n",
    "from echotorch.utils.matrix_generation import *\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from operator import itemgetter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_loaders(dataset_size=100, use_bw=False):\n",
    "\treduced_train_size = int(60000 * dataset_size / 100)\n",
    "\n",
    "\ttrain_dataset = datasets.MNIST('../Hyperdimensional/Datasets/Processed/', train=True, download=False,\n",
    "\t                       transform=transforms.Compose([\n",
    "\t                           transforms.ToTensor(),\n",
    "\t                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "\t                       ]))\n",
    "\n",
    "\ttest_dataset = datasets.MNIST('../Hyperdimensional/Datasets/Processed/', train=False, transform=transforms.Compose([\n",
    "\t                           transforms.ToTensor(),\n",
    "\t                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "\t                       ]))\n",
    "\n",
    "\treduced_indices = list(range(60000))\n",
    "\tnp.random.shuffle(reduced_indices)\n",
    "\treduced_indices = reduced_indices[:reduced_train_size]\n",
    "\treduced_sampler = SubsetRandomSampler(reduced_indices)\n",
    "\n",
    "\ttest_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\treduced_train_loader = DataLoader(train_dataset, batch_size=1, sampler=reduced_sampler)\n",
    "\n",
    "\ttest_imgs = torch.empty((10000, 28*28))\n",
    "\ttest_labels = torch.empty((10000, 1))\n",
    "\n",
    "\tfor batch_num, (data, label) in enumerate(test_loader):\n",
    "\t\timg = torch.flatten(data).to(torch.float)\n",
    "\n",
    "\t\tif use_bw:\n",
    "\t\t\tthreshold = (torch.max(img) - torch.min(img)) / 2\n",
    "\t\t\timg = (img > threshold).to(torch.float)\n",
    "\n",
    "\t\ttest_imgs[batch_num] = img\n",
    "\t\ttest_labels[batch_num] = torch.tensor(label).to(torch.float)\n",
    "\n",
    "\treduced_train_imgs = torch.empty((reduced_train_size, 28*28))\n",
    "\treduced_train_labels = torch.empty((reduced_train_size, 10))\n",
    "\n",
    "\tfor batch_num, (data, label) in enumerate(reduced_train_loader):\n",
    "\t\timg = torch.flatten(data).to(torch.float)\n",
    "\n",
    "\t\tif use_bw:\n",
    "\t\t\tthreshold = (torch.max(img) - torch.min(img)) / 2\n",
    "\t\t\timg = (img > threshold).to(torch.float)\n",
    "\n",
    "\t\treduced_train_imgs[batch_num] = img\n",
    "\t\treduced_train_labels[batch_num] = torch.zeros(10)\n",
    "\t\treduced_train_labels[batch_num][label] = torch.tensor(1).to(torch.float)\n",
    "\n",
    "\treturn reduced_train_imgs, reduced_train_labels, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# np_labels = np.where(reduced_train_labels.numpy() == 1)\n",
    "# label_hist = np.histogram(np_labels, bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "#\n",
    "# np_img = reduced_train_imgs[0].numpy().reshape((28, 28))\n",
    "# lbl = reduced_train_labels[0].numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_model(res_size, alpha, sparsity):\n",
    "\ttorch.cuda.empty_cache()\n",
    "\tesn = ESN(\n",
    "\t\tinput_dim=28*28,\n",
    "\t\thidden_dim=res_size,\n",
    "\t\toutput_dim=10,\n",
    "\t\t# w_sparsity=sparsity,\n",
    "\t\t# leaky_rate=alpha,\n",
    "\t\tw_generator=MatrixGenerator(),\n",
    "\t\twbias_generator=MatrixGenerator(),\n",
    "\t\twin_generator=MatrixGenerator()\n",
    "\t).to(device)\n",
    "\n",
    "\t# for input, label in train_loader:\n",
    "\tinput = reduced_train_imgs.view(1, -1, 28*28).to(torch.float).to(device)\n",
    "\tlabel = reduced_train_labels.view(1, -1, 10).to(torch.float).to(device)\n",
    "\tprint(f'Training shape {input.shape}')\n",
    "\tesn(input, label)\n",
    "\n",
    "\tesn.finalize()\n",
    "\n",
    "\treturn esn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test_model(model, res_size, alpha, sparsity):\n",
    "\taccuracy = 0\n",
    "\tresults = np.zeros(10000)\n",
    "\n",
    "\tfor num, (img, label) in enumerate(test_loader):\n",
    "\t\tlabel = label.item()\n",
    "\t\tresult = model(img.view(1, -1, 28*28).to(torch.float).to(device))\n",
    "\t\tprediction = softmax(result.cpu().numpy()).flatten()\n",
    "\t\tprediction = np.argmax(prediction, 0)\n",
    "\n",
    "\t\taccuracy += prediction == label\n",
    "\t\tresults[num] = prediction\n",
    "\n",
    "\tprint(f'{res_size} nodes, {alpha}, {sparsity}: {accuracy / 100}')\n",
    "\treturn accuracy / 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faae1a43f23445eeb09a4ec681a3d3eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\ruchi\\Anaconda3\\envs\\EE510\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e3a8385676a4717ac9c518a520d9a1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "Training shape torch.Size([1, 60000, 784])\n",
      "500 nodes, 0.95, 0.25: 89.4\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "SIZES = [500, 550, 600, 650, 700, 750, 800]\n",
    "ALPHA = [0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "SPARSITY = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "# for res_size in tqdm(SIZES):\n",
    "# \tfor alpha in tqdm(ALPHA):\n",
    "# \t\tfor sparsity in SPARSITY:\n",
    "# \t\t\tmodel = train_model(res_size, alpha, sparsity)\n",
    "# \t\t\taccuracy = test_model(model, res_size, alpha, sparsity)\n",
    "# \t\t\tstats[(res_size, alpha, sparsity)] = accuracy\n",
    "\n",
    "# res_size = 650\n",
    "# for exp_num in trange(10):\n",
    "# \tfor alpha in ALPHA:\n",
    "# \t\tfor sparsity in SPARSITY:\n",
    "# \t\t\tmodel = train_model(res_size, alpha, sparsity)\n",
    "# \t\t\taccuracy = test_model(model, res_size, alpha, sparsity)\n",
    "#\n",
    "# \t\t\tif (alpha, sparsity) in stats:\n",
    "# \t\t\t\tstats[(alpha, sparsity)].append(accuracy)\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tstats[(alpha, sparsity)] = [accuracy]\n",
    "\n",
    "for dataset_size in tqdm([100]):\n",
    "\tstats = {}\n",
    "\treduced_train_imgs, reduced_train_labels, test_loader = create_loaders(dataset_size, False)\n",
    "\n",
    "\tfor exp_num in trange(1):\n",
    "\t\tfor res_size in [500]:\n",
    "\t\t\tmodel = train_model(res_size, alpha=0.95, sparsity=0.25)\n",
    "\t\t\taccuracy = test_model(model, res_size, alpha=0.95, sparsity=0.25)\n",
    "\n",
    "\t\t\tif res_size in stats:\n",
    "\t\t\t\tstats[res_size].append(accuracy)\n",
    "\t\t\telse:\n",
    "\t\t\t\tstats[res_size] = [accuracy]\n",
    "\n",
    "\tresults[dataset_size] = stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lists = sorted(stats.items())\n",
    "x, y = zip(*lists)\n",
    "y = np.asarray(y)\n",
    "\n",
    "fig, ax = plt.subplots(6)\n",
    "\n",
    "for plot_num in range(6):\n",
    "\tmean_accuracy = np.mean(y, axis=1)\n",
    "\terror_accuracy = np.std(y, axis=1)\n",
    "\tax[plot_num].errorbar(SPARSITY, mean_accuracy[plot_num*5 : plot_num*5+5], yerr=error_accuracy[plot_num*5 : plot_num*5+5], ecolor='red')\n",
    "\tax[plot_num].set_title(f'Leakage {ALPHA[plot_num]}')\n",
    "\tax[plot_num].set_xticks(SPARSITY)\n",
    "\tax[plot_num].set_xlabel('Sparsity')\n",
    "\tax[plot_num].set_ylabel('Accuracy %')\n",
    "\tax[plot_num].set_ylim(np.min(mean_accuracy)-0.25, np.max(mean_accuracy)+0.25)\n",
    "fig.set_size_inches(5, 10)\n",
    "fig.tight_layout()\n",
    "fig.savefig('res_650.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for size in [100, 75, 50, 25]:\n",
    "\tlists = sorted(results[size].items())\n",
    "\tx, y = zip(*lists)\n",
    "\ty = np.asarray(y)\n",
    "\n",
    "\tmean_accuracy = np.mean(y, axis=1)\n",
    "\terror_accuracy = np.std(y, axis=1)\n",
    "\n",
    "\tax.plot(x, mean_accuracy, label=str(size))\n",
    "\tax.set_title('Accuracy vs reservoir size')\n",
    "\tax.set_xlabel('Reservoir nodes')\n",
    "\tax.set_ylabel('Accuracy %')\n",
    "\tax.set_xticks(range(450, 851, 50))\n",
    "ax.legend()\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig('res_nodes_reduced.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lists = sorted(stats.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "fig, ax = plt.subplots(10, 5)\n",
    "fig.set_size_inches(15, 25)\n",
    "fig.set_tight_layout({'pad': 1})\n",
    "\n",
    "min_val = min(lists, key=itemgetter(1))[1]\n",
    "max_val = max(lists, key=itemgetter(1))[1]\n",
    "\n",
    "ax_i = 0\n",
    "for res_size in SIZES:\n",
    "\tax_j = 0\n",
    "\tfor alpha in ALPHA:\n",
    "\t\tvalues = [(elem[0][2], elem[1]) for elem in lists\n",
    "\t\t          if elem[0][0] == res_size and elem[0][1] == alpha]\n",
    "\n",
    "\t\tax[ax_i][ax_j].set_ylim(min_val-1, max_val+1)\n",
    "\t\tmaximum = ''\n",
    "\t\ttry:\n",
    "\t\t\tmaximum = max(values, key=itemgetter(1))[1]\n",
    "\t\texcept ValueError:\n",
    "\t\t\tpass\n",
    "\t\tax[ax_i][ax_j].plot(*zip(*values), label=str(maximum))\n",
    "\n",
    "\t\tax[ax_i][ax_j].set_title(f'{res_size} nodes, {alpha} leakage')\n",
    "\t\tax[ax_i][ax_j].legend()\n",
    "\t\tax_j += 1\n",
    "\tax_i += 1\n",
    "\n",
    "fig.savefig('res_650.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('results_reduced.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in lists))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file = []\n",
    "with open('results_reduced.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "\t    results_file.append(eval(line))\n",
    "\n",
    "results = {}\n",
    "\n",
    "for result in results_file:\n",
    "\tfor key, value in result.items():\n",
    "\t\tresults[key] = value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}